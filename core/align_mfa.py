"""
Prepare files for MFA, execute MFA, and parse resulting TextGrid.

This module handles the integration with Montreal Forced Aligner (MFA) for
forced alignment of audio with transcript text. It prepares the required
corpus structure, executes MFA alignment, corrects any "<unk>" tags in TextGrids,
and parses the resulting TextGrid to extract precise word and sentence timing information.

The module assumes that MFA is installed and available in the system PATH.

Main functions:
- run_mfa_alignment: Prepare corpus, execute MFA alignment, return TextGrid path
- correct_textgrid_unks: Replace "<unk>" entries with words from transcript
- parse_textgrid_for_sentences: Parse TextGrid + transcript to produce sentence list with timestamps

Notes:
- MFA expects WAV+lab/txt pairs with matching basenames
- This implementation includes automatic correction of MFA alignment failures
- Uses heuristics to map sentences to aligned word sequences
"""
from pathlib import Path
import subprocess
import shutil
import logging
from textgrid import TextGrid
import re
from typing import List, Dict, Any
from core.config import MFA_BEAM, MFA_RETRY_BEAM, MIN_WORD_ALIGNMENT_RATIO


def run_mfa_alignment(wav_path: Path, transcript_path: Path, out_dir: Path, mfa_lang: str = "spanish_mfa") -> Path:
    """
    Prepare a small corpus for MFA, copy WAV and transcript to matching basename, and execute MFA alignment.

    This function creates the required corpus structure for MFA by copying the audio file
    and transcript to a corpus directory with matching basenames. It then executes the
    MFA alignment command and returns the path to the generated TextGrid file.

    MFA requires:
    - Audio file in WAV format (16kHz, mono, 16-bit PCM)
    - Transcript file with same basename as audio file
    - Acoustic model and pronunciation dictionary for the target language

    Args:
        wav_path: Path to preprocessed WAV file (16kHz, mono, 16-bit PCM)
        transcript_path: Path to text file containing orthographic transcription
        out_dir: Directory where MFA will deposit results
        mfa_lang: Name of language model for MFA (e.g. 'spanish', 'english')

    Returns:
        Path: Path to TextGrid file generated by MFA

    Raises:
        subprocess.CalledProcessError: If MFA alignment command fails
        FileNotFoundError: If TextGrid is not found after MFA execution

    Example:
        >>> textgrid_path = run_mfa_alignment(
        ...     Path('audio.wav'),
        ...     Path('transcript.txt'),
        ...     Path('output'),
        ...     'spanish_mfa'
        ... )
    """
    logger = logging.getLogger(__name__)
    wav_path = Path(wav_path)
    transcript_path = Path(transcript_path)
    out_dir = Path(out_dir)

    # Prepare corpus dir
    corpus_dir = out_dir / "corpus"
    if corpus_dir.exists():
        shutil.rmtree(corpus_dir)
    corpus_dir.mkdir(parents=True)

    # MFA expects: wav file(s) + matching .lab/.txt transcripts with same basename
    basename = wav_path.stem
    wav_dst = corpus_dir / f"{basename}.wav"
    txt_dst = corpus_dir / f"{basename}.lab"  # MFA accepts .lab or .txt files
    shutil.copy(wav_path, wav_dst)
    shutil.copy(transcript_path, txt_dst)

    # Run MFA align
    mfa_out_dir = out_dir / "mfa_aligned"
    if mfa_out_dir.exists():
        shutil.rmtree(mfa_out_dir)
    mfa_out_dir.mkdir(parents=True)

    # Command example:
    # mfa align <corpus_dir> <dictionary_or_lang> <acoustic_model> <output_dir> --clean
    # We assume the user has installed an acoustic/lexicon model named mfa_lang
    # and a dictionary with the same name.
    # Using higher beam parameters for difficult alignments
    cmd = [
        "mfa", "align",
        str(corpus_dir),
        mfa_lang,
        mfa_lang,
        str(mfa_out_dir),
        "--clean",
        "--beam", str(MFA_BEAM),        # Higher beam width for difficult alignments
        "--retry_beam", str(MFA_RETRY_BEAM)   # Higher retry beam
    ]
    logger.debug("Running MFA: %s", " ".join(cmd))

    try:
        subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as e:
        logger.error("MFA failed with return code %s. Please ensure MFA is installed and models are available.", e.returncode)
        raise

    # Search for TextGrid in output (MFA writes TextGrid files within the mfa_aligned subdirectory)
    tg = None

    # First, try to find TextGrid directly in the mfa_aligned directory
    for p in mfa_out_dir.glob("*.TextGrid"):
        tg = p
        break

    # If not found, MFA creates a subdirectory with the basename inside mfa_aligned
    if tg is None:
        nested = mfa_out_dir / basename
        if nested.exists():
            tg = next(nested.glob("*.TextGrid"), None)

    # If still not found, search recursively in all subdirectories of mfa_aligned
    if tg is None:
        for p in mfa_out_dir.rglob("*.TextGrid"):
            tg = p
            break

    if tg is None:
        logger.error("No TextGrid found after running MFA. Please check MFA logs in stdout/stderr.")
        raise FileNotFoundError("TextGrid not generated")

    logger.info("TextGrid generated at: %s", tg)
    return tg


def correct_textgrid_unks(textgrid_path: Path, transcript_path: Path) -> Path:
    """
    Correct "<unk>" tags in TextGrid by replacing with words from original transcript.

    This function identifies "<unk>" entries in the word tier of a TextGrid file
    and replaces them with the corresponding words from the Whisper transcript.
    This ensures proper alignment by preserving word continuity, preventing premature
    clip segmentation due to unrecognized words.

    Args:
        textgrid_path: Path to the MFA-generated TextGrid file with potential "<unk>" entries
        transcript_path: Path to the original Whisper transcript text file

    Returns:
        Path: Path to the corrected TextGrid file (appends "_corrected" to filename)

    Raises:
        ValueError: If no word tier found or transcript parsing fails
        FileNotFoundError: If input files don't exist

    Example:
        >>> corrected_path = correct_textgrid_unks('alignment.TextGrid', 'transcript.txt')
        >>> # alignment_corrected.TextGrid created with "<unk>" replaced by transcript words
    """
    logger = logging.getLogger(__name__)
    textgrid_path = Path(textgrid_path)
    transcript_path = Path(transcript_path)

    # Load TextGrid file
    try:
        tg = TextGrid.fromFile(str(textgrid_path))
    except Exception as e:
        logger.error("Error loading TextGrid for correction: %s", e)
        raise

    # Read original transcript and split into words
    with open(transcript_path, 'r', encoding='utf-8') as f:
        full_transcript = f.read().strip()

    # Split transcript into words (similar to sentence cleaning but for all words)
    # Handle punctuation and case
    transcript_words = re.findall(r'\b\w+\b', full_transcript.lower())
    transcript_words = [w.strip() for w in transcript_words if w.strip()]

    if not transcript_words:
        logger.error("No words found in transcript for TextGrid correction")
        raise ValueError("Empty transcript for TextGrid correction")

    logger.info("Transcript contains %d words for potential <unk> replacement", len(transcript_words))

    # Find word tier in TextGrid (same logic as parse_textgrid_for_sentences)
    word_tier = None
    for tier in tg.tiers:
        if hasattr(tier, 'intervals') and len(tier.intervals) > 0:
            word_tier = tier
            break

    if word_tier is None:
        logger.error("No word tier found in TextGrid for correction")
        raise ValueError("No word tier found in TextGrid for correction")

    # Track replacements
    unk_count = 0
    transcript_idx = 0  # Index in transcript words

    # Iterate through intervals in word tier
    for i, interval in enumerate(word_tier.intervals):
        mark_text = interval.mark.strip()

        if mark_text == '':
            # Empty/silence interval - skip
            continue

        if mark_text == '<unk>':
            # Found unk to replace
            if transcript_idx < len(transcript_words):
                # Replace with next word from transcript
                original_word = transcript_words[transcript_idx]
                interval.mark = original_word
                logger.info("Replaced <unk> with '%s' at interval %d (%.3f-%.3f)",
                          original_word, i, interval.minTime, interval.maxTime)
                unk_count += 1
                transcript_idx += 1
            else:
                logger.warning("No more words in transcript to replace <unk> at interval %d", i)
                break
        else:
            # Normal word - advance transcript index if it matches
            # Clean mark for comparison
            clean_mark = re.sub(r'[^\wáéíóúñüÁÉÍÓÚÑÜ]', '', mark_text.lower())

            # Try to sync with transcript
            while (transcript_idx < len(transcript_words) and
                   transcript_idx + unk_count < i + 1):  # Rough sync check
                if clean_mark in transcript_words[transcript_idx]:
                    transcript_idx += 1
                    break
                transcript_idx += 1

    logger.info("TextGrid correction completed: %d '<unk>' entries replaced", unk_count)

    # Save corrected TextGrid with new filename
    corrected_path = textgrid_path.with_name(f"{textgrid_path.stem}_corrected{textgrid_path.suffix}")
    try:
        tg.write(str(corrected_path))
        logger.info("Corrected TextGrid saved at: %s", corrected_path)
    except Exception as e:
        logger.error("Failed to save corrected TextGrid: %s", e)
        raise

    return corrected_path


def parse_textgrid_for_sentences(textgrid_path: Path, transcript_path: Path) -> List[Dict[str, Any]]:
    """
    Parse TextGrid and original transcript to return list of sentences with start/end times in seconds.

    This function implements a heuristic approach to align transcribed sentences with
    MFA-generated word timestamps:

    1. Read word tier from TextGrid (find 'words' tier or first tier with intervals)
    2. Build list of words with their timestamps
    3. Split orthographic transcript into sentences (by punctuation)
    4. Attempt to map each sentence to contiguous subsequence of aligned words

    Args:
        textgrid_path: Path to MFA-generated TextGrid file
        transcript_path: Path to original transcript text file

    Returns:
        List[Dict[str, Any]]: List of sentence dictionaries containing:
            - sentence: Original sentence text
            - start: Start time in seconds (float)
            - end: End time in seconds (float)

    Raises:
        ValueError: If no word tier found in TextGrid or no sentences can be aligned
        FileNotFoundError: If input files don't exist

    Example:
        >>> sentences = parse_textgrid_for_sentences('alignment.TextGrid', 'transcript.txt')
        >>> for sent in sentences:
        ...     print(f"{sent['sentence']}: {sent['start']:.2f}s - {sent['end']:.2f}s")
    """
    logger = logging.getLogger(__name__)
    textgrid_path = Path(textgrid_path)
    transcript_path = Path(transcript_path)

    # Load TextGrid file generated by MFA
    try:
        tg = TextGrid.fromFile(textgrid_path)
    except Exception as e:
        logger.error("Error loading TextGrid: %s", e)
        raise

    # Read original transcript text
    with open(transcript_path, 'r', encoding='utf-8') as f:
        full_transcript = f.read().strip()

    # Find word tier in TextGrid (usually named 'words' or similar)
    word_tier = None
    for tier in tg.tiers:
        if hasattr(tier, 'intervals') and len(tier.intervals) > 0:
            # Take first tier that has intervals (typically words)
            word_tier = tier
            break

    if word_tier is None:
        logger.error("No word tier found in TextGrid")
        raise ValueError("No word tier found in TextGrid")

    # Extract words with timestamps from the word tier
    words_with_times = []
    for interval in word_tier.intervals:
        # Ignore silences and empty intervals
        if interval.mark.strip() and interval.mark != '':
            words_with_times.append({
                'word': interval.mark,
                'start': interval.minTime,
                'end': interval.maxTime
            })

    if not words_with_times:
        logger.error("No aligned words found in TextGrid")
        raise ValueError("No aligned words found in TextGrid")

    # Split transcript into sentences using regex pattern
    # Look for sentence endings: . ! ? optionally followed by spaces and quotes
    sentence_pattern = r'(?<=[.!?])\s+(?="*[A-ZÁÉÍÓÚÑ])|(?<=[.!?])(?=\s*$)'
    sentences = re.split(sentence_pattern, full_transcript)

    # Clean empty sentences and strip whitespace
    sentences = [s.strip() for s in sentences if s.strip()]

    if not sentences:
        logger.warning("Could not split transcript into sentences")
        # Create single sentence with full text
        sentences = [full_transcript]

    # Map sentences to aligned words
    sentence_data = []
    word_idx = 0

    for sentence in sentences:
        if not sentence:
            continue

        # Clean punctuation from sentence for matching
        clean_sentence = re.sub(r'[^\w\sáéíóúñüÁÉÍÓÚÑÜ]', '', sentence.lower())

        # Search for sentence words in aligned words
        sentence_words = []
        start_time = None
        end_time = None

        # Attempt word-by-word matching
        sentence_word_list = clean_sentence.split()
        matched_words = 0

        for i, sentence_word in enumerate(sentence_word_list):
            # Find next matching word
            found = False
            for j in range(word_idx, len(words_with_times)):
                aligned_word = words_with_times[j]['word'].lower()
                # Flexible comparison: remove punctuation from aligned words too
                clean_aligned = re.sub(r'[^\wáéíóúñüÁÉÍÓÚÑÜ]', '', aligned_word)

                if clean_aligned == sentence_word:
                    sentence_words.append(words_with_times[j])
                    if start_time is None:
                        start_time = words_with_times[j]['start']
                    end_time = words_with_times[j]['end']
                    word_idx = j + 1
                    matched_words += 1
                    found = True
                    break

            if not found:
                logger.warning("Could not align word '%s' in sentence: %s", sentence_word, sentence)
                break

        # If sufficient words aligned, consider valid
        if matched_words >= len(sentence_word_list) * MIN_WORD_ALIGNMENT_RATIO and sentence_words:
            sentence_data.append({
                'sentence': sentence,
                'start': start_time,
                'end': end_time
            })
            logger.debug("Aligned sentence: '%s' (%.3f-%.3f)", sentence[:50], start_time, end_time)
        else:
            logger.warning("Sentence with too few aligned words, discarding: %s", sentence)

    if not sentence_data:
        logger.error("Could not align sentences. Please verify that transcript and audio match.")
        raise ValueError("No sentences could be aligned")

    logger.info("Aligned %d sentences from %d words", len(sentence_data), len(words_with_times))
    return sentence_data
