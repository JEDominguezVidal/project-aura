"""
Prepare files for MFA, execute MFA, and parse resulting TextGrid.

This module handles the integration with Montreal Forced Aligner (MFA) for
forced alignment of audio with transcript text. It prepares the required
corpus structure, executes MFA alignment, and parses the resulting TextGrid
to extract precise word and sentence timing information.

The module assumes that MFA is installed and available in the system PATH.

Main functions:
- run_mfa_alignment: Prepare corpus, execute MFA alignment, return TextGrid path
- parse_textgrid_for_sentences: Parse TextGrid + transcript to produce sentence list with timestamps

Notes:
- MFA expects WAV+lab/txt pairs with matching basenames
- This implementation uses heuristics to map sentences to aligned word sequences
"""
from pathlib import Path
import subprocess
import shutil
import logging
from textgrid import TextGrid
import re
from typing import List, Dict, Any
from utils import setup_logger


def run_mfa_alignment(logger: logging.Logger, wav_path: Path, transcript_path: Path, out_dir: Path, mfa_lang: str = "spanish_mfa") -> Path:
    """
    Prepare a small corpus for MFA, copy WAV and transcript to matching basename, and execute MFA alignment.

    This function creates the required corpus structure for MFA by copying the audio file
    and transcript to a corpus directory with matching basenames. It then executes the
    MFA alignment command and returns the path to the generated TextGrid file.

    MFA requires:
    - Audio file in WAV format (16kHz, mono, 16-bit PCM)
    - Transcript file with same basename as audio file
    - Acoustic model and pronunciation dictionary for the target language

    Args:
        logger: Logger instance for logging messages
        wav_path: Path to preprocessed WAV file (16kHz, mono, 16-bit PCM)
        transcript_path: Path to text file containing orthographic transcription
        out_dir: Directory where MFA will deposit results
        mfa_lang: Name of language model for MFA (e.g. 'spanish', 'english')

    Returns:
        Path: Path to TextGrid file generated by MFA

    Raises:
        subprocess.CalledProcessError: If MFA alignment command fails
        FileNotFoundError: If TextGrid is not found after MFA execution

    Example:
        >>> textgrid_path = run_mfa_alignment(
        ...     logger,
        ...     Path('audio.wav'),
        ...     Path('transcript.txt'),
        ...     Path('output'),
        ...     'spanish_mfa'
        ... )
    """
    logger = logger
    wav_path = Path(wav_path)
    transcript_path = Path(transcript_path)
    out_dir = Path(out_dir)

    # Prepare corpus dir
    corpus_dir = out_dir / "corpus"
    if corpus_dir.exists():
        shutil.rmtree(corpus_dir)
    corpus_dir.mkdir(parents=True)

    # MFA expects: wav file(s) + matching .lab/.txt transcripts with same basename
    basename = wav_path.stem
    wav_dst = corpus_dir / f"{basename}.wav"
    txt_dst = corpus_dir / f"{basename}.lab"  # MFA accepts .lab or .txt files
    shutil.copy(wav_path, wav_dst)
    shutil.copy(transcript_path, txt_dst)

    # Run MFA align
    mfa_out_dir = out_dir / "mfa_aligned"
    if mfa_out_dir.exists():
        shutil.rmtree(mfa_out_dir)
    mfa_out_dir.mkdir(parents=True)

    # Command example:
    # mfa align <corpus_dir> <dictionary_or_lang> <acoustic_model> <output_dir> --clean
    # We assume the user has installed an acoustic/lexicon model named mfa_lang
    # and a dictionary with the same name.
    # Using higher beam parameters for difficult alignments
    cmd = [
        "mfa", "align",
        str(corpus_dir),
        mfa_lang,
        mfa_lang,
        str(mfa_out_dir),
        "--clean",
        "--beam", "100",        # Higher beam width for difficult alignments
        "--retry_beam", "400"   # Higher retry beam
    ]
    logger.debug("Running MFA: %s", " ".join(cmd))

    try:
        subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as e:
        logger.error("MFA failed with return code %s. Please ensure MFA is installed and models are available.", e.returncode)
        raise

    # Search for TextGrid in output (MFA writes TextGrid files within the mfa_aligned subdirectory)
    tg = None

    # First, try to find TextGrid directly in the mfa_aligned directory
    for p in mfa_out_dir.glob("*.TextGrid"):
        tg = p
        break

    # If not found, MFA creates a subdirectory with the basename inside mfa_aligned
    if tg is None:
        nested = mfa_out_dir / basename
        if nested.exists():
            tg = next(nested.glob("*.TextGrid"), None)

    # If still not found, search recursively in all subdirectories of mfa_aligned
    if tg is None:
        for p in mfa_out_dir.rglob("*.TextGrid"):
            tg = p
            break

    if tg is None:
        logger.error("No TextGrid found after running MFA. Please check MFA logs in stdout/stderr.")
        raise FileNotFoundError("TextGrid not generated")

    logger.info("TextGrid generated at: %s", tg)
    return tg


def parse_textgrid_for_sentences(logger: logging.Logger, textgrid_path: Path, transcript_path: Path) -> List[Dict[str, Any]]:
    """
    Parse TextGrid and original transcript to return list of sentences with start/end times in seconds.

    This function implements a heuristic approach to align transcribed sentences with
    MFA-generated word timestamps:

    1. Read word tier from TextGrid (find 'words' tier or first tier with intervals)
    2. Build list of words with their timestamps
    3. Split orthographic transcript into sentences (by punctuation)
    4. Attempt to map each sentence to contiguous subsequence of aligned words

    Args:
        logger: Logger instance for logging messages
        textgrid_path: Path to MFA-generated TextGrid file
        transcript_path: Path to original transcript text file

    Returns:
        List[Dict[str, Any]]: List of sentence dictionaries containing:
            - sentence: Original sentence text
            - start: Start time in seconds (float)
            - end: End time in seconds (float)

    Raises:
        ValueError: If no word tier found in TextGrid or no sentences can be aligned
        FileNotFoundError: If input files don't exist

    Example:
        >>> sentences = parse_textgrid_for_sentences(logger, 'alignment.TextGrid', 'transcript.txt')
        >>> for sent in sentences:
        ...     print(f"{sent['sentence']}: {sent['start']:.2f}s - {sent['end']:.2f}s")
    """
    logger = logger
    textgrid_path = Path(textgrid_path)
    transcript_path = Path(transcript_path)

    # Load TextGrid file generated by MFA
    try:
        tg = TextGrid.fromFile(textgrid_path)
    except Exception as e:
        logger.error("Error loading TextGrid: %s", e)
        raise

    # Read original transcript text
    with open(transcript_path, 'r', encoding='utf-8') as f:
        full_transcript = f.read().strip()

    # Find word tier in TextGrid (usually named 'words' or similar)
    word_tier = None
    for tier in tg.tiers:
        if hasattr(tier, 'intervals') and len(tier.intervals) > 0:
            # Take first tier that has intervals (typically words)
            word_tier = tier
            break

    if word_tier is None:
        logger.error("No word tier found in TextGrid")
        raise ValueError("No word tier found in TextGrid")

    # Extract words with timestamps from the word tier
    words_with_times = []
    for interval in word_tier.intervals:
        # Ignore silences and empty intervals
        if interval.mark.strip() and interval.mark != '':
            words_with_times.append({
                'word': interval.mark,
                'start': interval.minTime,
                'end': interval.maxTime
            })

    if not words_with_times:
        logger.error("No aligned words found in TextGrid")
        raise ValueError("No aligned words found in TextGrid")

    # Split transcript into sentences using regex pattern
    # Look for sentence endings: . ! ? optionally followed by spaces and quotes
    sentence_pattern = r'(?<=[.!?])\s+(?="*[A-ZÁÉÍÓÚÑ])|(?<=[.!?])(?=\s*$)'
    sentences = re.split(sentence_pattern, full_transcript)

    # Clean empty sentences and strip whitespace
    sentences = [s.strip() for s in sentences if s.strip()]

    if not sentences:
        logger.warning("Could not split transcript into sentences")
        # Create single sentence with full text
        sentences = [full_transcript]

    # Map sentences to aligned words
    sentence_data = []
    word_idx = 0

    for sentence in sentences:
        if not sentence:
            continue

        # Clean punctuation from sentence for matching
        clean_sentence = re.sub(r'[^\w\sáéíóúñüÁÉÍÓÚÑÜ]', '', sentence.lower())

        # Search for sentence words in aligned words
        sentence_words = []
        start_time = None
        end_time = None

        # Attempt word-by-word matching
        sentence_word_list = clean_sentence.split()
        matched_words = 0

        for i, sentence_word in enumerate(sentence_word_list):
            # Find next matching word
            found = False
            for j in range(word_idx, len(words_with_times)):
                aligned_word = words_with_times[j]['word'].lower()
                # Flexible comparison: remove punctuation from aligned words too
                clean_aligned = re.sub(r'[^\wáéíóúñüÁÉÍÓÚÑÜ]', '', aligned_word)

                if clean_aligned == sentence_word:
                    sentence_words.append(words_with_times[j])
                    if start_time is None:
                        start_time = words_with_times[j]['start']
                    end_time = words_with_times[j]['end']
                    word_idx = j + 1
                    matched_words += 1
                    found = True
                    break

            if not found:
                logger.warning("Could not align word '%s' in sentence: %s", sentence_word, sentence)
                break

        # If sufficient words aligned (>20%), consider valid
        if matched_words >= len(sentence_word_list) * 0.2 and sentence_words:
            sentence_data.append({
                'sentence': sentence,
                'start': start_time,
                'end': end_time
            })
            logger.debug("Aligned sentence: '%s' (%.3f-%.3f)", sentence[:50], start_time, end_time)
        else:
            logger.warning("Sentence with too few aligned words, discarding: %s", sentence)

    if not sentence_data:
        logger.error("Could not align sentences. Please verify that transcript and audio match.")
        raise ValueError("No sentences could be aligned")

    logger.info("Aligned %d sentences from %d words", len(sentence_data), len(words_with_times))
    return sentence_data
